# PRD015: Observabilidade e M√©tricas para Skybridge

**Status:** üìã Proposta
**Data:** 2026-01-17
**Autor:** Sky
**Vers√£o:** 1.0
**Relacionado:** Problema #5 (ANALISE_PROBLEMAS_ATUAIS.md)

---

## üìã Resumo Executivo

Implementar sistema de **m√©tricas e observabilidade** para permitir tomada de decis√µes baseada em dados, identificar gargalos de performance e justificar investimentos em infraestrutura.

### Problema
Atualmente o Skybridge **n√£o coleta m√©tricas agregadas**, tornando imposs√≠vel responder perguntas cr√≠ticas como:
- Quantos jobs por hora estamos processando?
- Qual √© o tempo m√©dio de execu√ß√£o dos agentes?
- Qual taxa de erro?
- Quando precisamos escalar horizontalmente?
- Quanto estamos gastando com a API do Claude?

### Solu√ß√£o
Implementar sistema de m√©tricas em camadas:
1. **Camada 1:** Logs estruturados (‚úÖ j√° existe)
2. **Camada 2:** M√©tricas agregadas (üî® a implementar)
3. **Camada 3:** Dashboards e alertas (üìÖ Fase 2)
4. **Camada 4:** Rastreamento distribu√≠do (‚úÖ correlation_id j√° existe)

---

## üéØ Objetivos

### Prim√°rios
- [ ] Coletar m√©tricas de **throughput** (jobs/hora)
- [ ] Medir **lat√™ncia** de cada fase (webhook ‚Üí agent ‚Üí Trello)
- [ ] Calcular **taxa de erro** por tipo de job
- [ ] Monitorar **recursos** (mem√≥ria, CPU, fila)
- [ ] Rastrear **custos** da API Claude

### Secund√°rios
- [ ] Dashboard CLI para visualiza√ß√£o em tempo real
- [ ] Endpoint `/metrics` para integra√ß√£o com Prometheus
- [ ] Alertas autom√°ticos para SLO violations
- [ ] Relat√≥rios di√°rios de performance

### N√£o-Objetivos
- ‚ùå Substituir logs existentes (logs continuam como est√°)
- ‚ùå Implementar tracing distribu√≠do completo (OpenTelemetry = Fase 3)
- ‚ùå Dashboard web complexo (Grafana = futuro, usar CLI primeiro)

---

## üìä M√©tricas Propostas

### 1. M√©tricas de Neg√≥cio (Business Metrics)

| Nome | Tipo | Descri√ß√£o | Pergunta que Responde |
|------|------|-----------|----------------------|
| `jobs_total` | Counter | Total de jobs processados | "Quantos jobs processamos desde o in√≠cio?" |
| `jobs_success` | Counter | Jobs completados com sucesso | "Quantos deram certo?" |
| `jobs_failed` | Counter | Jobs que falharam | "Quantos falharam?" |
| `jobs_by_skill{skill}` | Counter | Jobs por tipo (resolve-issue, bug-simple, etc) | "Que tipo de issues chegam?" |
| `jobs_by_source{source}` | Counter | Jobs por origem (github, discord, etc) | "De onde v√™m os webhooks?" |
| `queue_size` | Gauge | Tamanho atual da fila | "Qual o backlog?" |

### 2. M√©tricas de Performance (Latency)

| Nome | Tipo | Unidade | Percentis |
|------|------|---------|-----------|
| `job_duration_seconds` | Histogram | segundos | p50, p95, p99 |
| `agent_duration_seconds` | Histogram | segundos | p50, p95, p99 |
| `webhook_to_queue_latency` | Histogram | segundos | p50, p95, p99 |
| `queue_to_agent_latency` | Histogram | segundos | p50, p95, p99 |
| `trello_api_duration_seconds` | Histogram | segundos | p50, p95, p99 |

### 3. M√©tricas de Recursos (System)

| Nome | Tipo | Unidade | Alerta |
|------|------|---------|--------|
| `worker_memory_bytes` | Gauge | bytes | > 2GB |
| `worker_cpu_percent` | Gauge | % | > 80% |
| `active_agents` | Gauge | count | > N (configur√°vel) |
| `worktree_count` | Gauge | count | > 100 |

### 4. M√©tricas de Custos (Cost)

| Nome | Tipo | Unidade | Derivada de |
|------|------|---------|------------|
| `claude_api_tokens_total` | Counter | tokens | Agent execution |
| `claude_api_cost_usd` | Gauge | USD | tokens √ó pre√ßo |
| `jobs_per_dollar` | Gauge | jobs/USD | jobs / cost |

---

## üèóÔ∏è Arquitetura Proposta

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Camada de Coleta (Instrumentation)                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ @measure_time decorator                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ metrics_store.increment("jobs_success")                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ metrics_store.record_histogram("duration", value)         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Camada de Armazenamento (Storage)                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ InMemoryMetricsStore                                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   - counters: Dict[str, float]                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   - gauges: Dict[str, float]                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   - histograms: Dict[str, List[MetricPoint]]             ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  FUTURO: Prometheus / StatsD / Redis                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Camada de Visualiza√ß√£o (Visualization)                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ CLI Dashboard (rich)                                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ HTTP Endpoint (/metrics)                                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ FUTURO: Grafana                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Camada de Alertas (Alerting)                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ AlertChecker                                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   - queue_size > 50 ‚Üí CR√çTICO                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   - error_rate > 10% ‚Üí AVISO                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   - p99_duration > 15min ‚Üí AVISO                          ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß Implementa√ß√£o

### Fase 1: Core (2-3 dias)

#### 1.1 InMemoryMetricsStore

```python
# src/runtime/observability/metrics.py

from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List
import threading

@dataclass
class MetricPoint:
    timestamp: datetime
    value: float
    tags: Dict[str, str]

class InMemoryMetricsStore:
    """Armazenamento em mem√≥ria de m√©tricas."""

    def __init__(self):
        self._counters: Dict[str, float] = defaultdict(float)
        self._gauges: Dict[str, float] = {}
        self._histograms: Dict[str, List[MetricPoint]] = defaultdict(list)
        self._lock = threading.Lock()

    def increment(self, name: str, value: float = 1.0, tags: Dict = None):
        """Incrementa contador."""
        key = self._make_key(name, tags)
        with self._lock:
            self._counters[key] += value

    def set_gauge(self, name: str, value: float, tags: Dict = None):
        """Define gauge."""
        key = self._make_key(name, tags)
        with self._lock:
            self._gauges[key] = value

    def record_histogram(self, name: str, value: float, tags: Dict = None):
        """Registra valor no histograma."""
        key = self._make_key(name, tags)
        with self._lock:
            self._histograms[key].append(MetricPoint(
                timestamp=datetime.utcnow(),
                value=value,
                tags=tags or {}
            ))
            # Mant√©m √∫ltimos 1000 pontos
            if len(self._histograms[key]) > 1000:
                self._histograms[key] = self._histograms[key][-1000:]

    def get_summary(self) -> Dict:
        """Retorna resumo agregado."""
        # ... implementa c√°lculo de avg, min, max, percentis
```

#### 1.2 Decorator @measure_time

```python
def measure_time(metric_name: str, tags: Dict = None):
    """Decorator para medir tempo de execu√ß√£o."""
    def decorator(func):
        async def wrapped(*args, **kwargs):
            start = datetime.utcnow()
            try:
                result = await func(*args, **kwargs)
                get_metrics_store().increment(f"{metric_name}_success", tags=tags)
                return result
            except Exception:
                get_metrics_store().increment(f"{metric_name}_failed", tags=tags)
                raise
            finally:
                duration = (datetime.utcnow() - start).total_seconds()
                get_metrics_store().record_histogram(
                    f"{metric_name}_duration_seconds",
                    duration,
                    tags=tags
                )
        return wrapped
    return decorator
```

#### 1.3 Integra√ß√£o no Worker

```python
# src/runtime/background/webhook_worker.py

from runtime.observability.metrics import get_metrics_store, measure_time

class WebhookWorker:
    async def start(self):
        while self._running:
            # Registra tamanho da fila
            get_metrics_store().set_gauge("queue_size", self.job_queue.size())

            job = await self.job_queue.wait_for_dequeue(timeout=1.0)

            if job:
                result = await self._execute_job_with_metrics(job)

                # Atualiza gauge ap√≥s processamento
                get_metrics_store().set_gauge("queue_size", self.job_queue.size())

    @measure_time("job_execution")
    async def _execute_job_with_metrics(self, job):
        tags = {
            "skill": self._get_skill_from_job(job),
            "source": job.event.source.value
        }

        result = await self.orchestrator.execute_job(job.job_id)

        if result.is_ok:
            get_metrics_store().increment("jobs_success", tags=tags)
        else:
            get_metrics_store().increment("jobs_failed", tags=tags)

        return result
```

### Fase 2: Visualiza√ß√£o (2-3 dias)

#### 2.1 Endpoint /metrics

```python
# src/runtime/delivery/routes.py

@app.get("/metrics")
async def get_metrics():
    """Retorna m√©tricas em formato Prometheus."""
    metrics = get_metrics_store().get_summary()

    lines = []

    # Contadores
    for name, value in metrics["counters"].items():
        lines.append(f"# HELP {name} Total count")
        lines.append(f"# TYPE {name} counter")
        lines.append(f"{name} {value}")

    # Gauges
    for name, value in metrics["gauges"].items():
        lines.append(f"# HELP {name} Current value")
        lines.append(f"# TYPE {name} gauge")
        lines.append(f"{name} {value}")

    # Histogramas (Prometheus format)
    for name, stats in metrics["histograms"].items():
        lines.append(f"# HELP {name} Duration in seconds")
        lines.append(f"# TYPE {name} histogram")
        lines.append(f"{name}_count {stats['count']}")
        lines.append(f"{name}_sum {stats['avg'] * stats['count']}")
        # _bucket com percentis

    return Response(content="\n".join(lines), media_type="text/plain")
```

#### 2.2 Dashboard CLI

```python
# src/runtime/observability/dashboard.py

from rich.console import Console
from rich.table import Table

def show_metrics_dashboard():
    """Mostra dashboard no terminal."""
    console = Console()
    metrics = get_metrics_store().get_summary()

    # Tabela de contadores
    counters = Table(title="üìä Contadores")
    counters.add_column("M√©trica")
    counters.add_column("Valor")

    for name, value in sorted(metrics["counters"].items()):
        counters.add_row(name, f"{value:,.0f}")

    # Tabela de lat√™ncia
    latency = Table(title="‚è±Ô∏è Lat√™ncia (segundos)")
    latency.add_column("M√©trica")
    latency.add_column("Avg")
    latency.add_column("P95")
    latency.add_column("P99")

    for name, stats in metrics["histograms"].items():
        if "duration" in name:
            latency.add_row(
                name,
                f"{stats['avg']:.1f}",
                f"{stats['p95']:.1f}",
                f"{stats['p99']:.1f}"
            )

    console.print(counters)
    console.print(latency)
```

### Fase 3: Alertas (1-2 dias)

```python
# src/runtime/observability/alerts.py

class AlertChecker:
    THRESHOLDS = {
        "queue_size_critical": 50,
        "queue_size_warning": 20,
        "job_duration_p99": 900,
        "error_rate_percent": 10,
    }

    def check_alerts(self) -> List[str]:
        """Verifica condi√ß√µes de alerta."""
        metrics = get_metrics_store().get_summary()
        alerts = []

        queue_size = metrics["gauges"].get("queue_size", 0)
        if queue_size > self.THRESHOLDS["queue_size_critical"]:
            alerts.append(f"üö® CR√çTICO: Fila com {queue_size} jobs")

        # ... mais verifica√ß√µes

        return alerts
```

---

## ‚úÖ Crit√©rios de Sucesso

### M√≠nimo Vi√°vel (MVP)
- [ ] `InMemoryMetricsStore` implementado
- [ ] Decorator `@measure_time` funcionando
- [ ] Worker coletando m√©tricas de jobs
- [ ] Endpoint `/metrics` retornando dados
- [ ] Dashboard CLI mostrando contadores e lat√™ncia

### Completo
- [ ] Todas as m√©tricas propostas coletadas
- [ ] Histogramas calculando percentis (p50, p95, p99)
- [ ] Alert checker funcionando
- [ ] Testes cobrindo camada de m√©tricas
- [ ] Documenta√ß√£o de como adicionar novas m√©tricas

### Stretch (Futuro)
- [ ] Integra√ß√£o com Prometheus
- [ ] Dashboard Grafana
- [ ] Alertas via PagerDuty/Slack
- [] Tracing distribu√≠do com OpenTelemetry

---

## üß™ Testes

```python
# tests/runtime/test_metrics.py

def test_counter_increment():
    store = InMemoryMetricsStore()
    store.increment("jobs_total")
    store.increment("jobs_total", value=5)

    summary = store.get_summary()
    assert summary["counters"]["jobs_total"] == 6

def test_histogram_percentiles():
    store = InMemoryMetricsStore()

    # Registra 100 medi√ß√µes
    for i in range(100):
        store.record_histogram("test", i)

    summary = store.get_summary()
    stats = summary["histograms"]["test"]

    assert stats["count"] == 100
    assert stats["min"] == 0
    assert stats["max"] == 99
    assert 45 <= stats["avg"] <= 55  # ~50

@pytest.mark.asyncio
async def test_measure_time_decorator():
    store = InMemoryMetricsStore()

    @measure_time("test_operation")
    async def operation():
        await asyncio.sleep(0.1)
        return "ok"

    result = await operation()

    summary = store.get_summary()
    assert "test_operation_success" in summary["counters"]
    assert "test_operation_duration_seconds" in summary["histograms"]
```

---

## üìÖ Roadmap

| Sprint | Dias | Entrega |
|--------|------|---------|
| **Sprint 1** | 2-3 | InMemoryMetricsStore + decorator + integra√ß√£o worker |
| **Sprint 2** | 2-3 | Endpoint /metrics + dashboard CLI |
| **Sprint 3** | 1-2 | Alert checker + testes |
| **Total** | **5-8 dias** | Sistema de m√©tricas completo |

---

## üîÑ Relacionamento com Outros PRDs

| PRD | Rela√ß√£o | Descri√ß√£o |
|-----|---------|-----------|
| **PRD013** | Depende | Agentes (PRD013) ser√£o instrumentados com m√©tricas |
| **PRD016** | Independente | Domain Events (PRD016) futuramente tamb√©m ter√£o m√©tricas |
| **PRD014** | Complementa | WebUI Dashboard pode consumir /metrics |

---

## üí≠ Perguntas Frequentes

**Q: Por que n√£o Prometheus desde o in√≠cio?**
A: `InMemoryMetricsStore` √© suficiente para MVP e simplifica setup. Prometheus pode ser adicionado depois sem mudar c√≥digo de instrumenta√ß√£o.

**Q: M√©tricas v√£o degradar performance?**
A: Impacto m√≠nimo (< 1%). Opera√ß√µes s√£o O(1) com lock threading. Mem√≥ria: ~1-2MB para 1000 pontos de histograma.

**Q: Como calcular percentis?**
A: Para MVP: ordenar valores e pegar √≠ndice. Para produ√ß√£o: usar t-digest ou Prometheus.

**Q: O que acontece quando reinicia o servidor?**
A: M√©tricas em mem√≥ria s√£o perdidas. Para persist√™ncia, adicionar Prometheus push gateway ou Redis.

---

## üìä Valor de Neg√≥cio

### Antes
> "Acho que estamos processando uns 10 jobs por hora... n√£o sei ao certo."

### Depois
> "Processamos **47 jobs/hora** nas √∫ltimas 24h, com **p95 de 8.3min** por job. Taxa de erro de **2.1%**. Precisamos escalar quando fila > 20."

**Benef√≠cios:**
- ‚úÖ Decis√µes baseadas em dados
- ‚úÖ Detec√ß√£o precoce de regress√µes
- ‚úÖ Justificativa clara para investimentos
- ‚úÖ SLA definido e monitorado

---

> "O que n√£o √© medido n√£o pode ser melhorado" ‚Äì made by Sky üìä
