# Guia de Pesquisa: QA Loop - Auto-Claude ‚Üí Skybridge

**Data:** 2026-01-14
**Analista:** Sky
**Objetivo:** Pesquisa profunda para implementar o recurso de QA Loop do Auto-Claude na Skybridge

---

## 1. Vis√£o Geral do QA Loop

### 1.1 Conceito

O **QA Loop** (Quality Assurance Loop) √© um sistema de valida√ß√£o autom√°tica e self-correcting que:

1. **Valida** implementa√ß√µes contra acceptance criteria
2. **Detecta** bugs, vulnerabilidades e regress√µes
3. **Aplica corre√ß√µes** automaticamente
4. **Revalida** at√© aprova√ß√£o ou limite de itera√ß√µes
5. **Escalona** para humanos quando necess√°rio

**Princ√≠pio Chave:** "You are the last line of defense. If you approve, feature ships."

---

### 1.2 Arquitetura de Auto-Claude

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Build Completa (Coders)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         QA Validation Loop (qa/loop.py)                  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Iteration 1‚îÇ  ‚îÇ  Iteration N ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ       ‚îÇ                  ‚îÇ                         ‚îÇ
‚îÇ       ‚ñº                  ‚ñº                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ QA Reviewer ‚îÇ    ‚îÇ QA Fixer  ‚îÇ   (Loop)    ‚îÇ
‚îÇ  ‚îÇ (reviewer.py)‚îÇ    ‚îÇ (fixer.py)   ‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ         ‚îÇ                     ‚îÇ                         ‚îÇ
‚îÇ         ‚îÇ                     ‚ñº                         ‚îÇ
‚îÇ         ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ         ‚îÇ              ‚îÇ  Fixed Issues ‚îÇ               ‚îÇ
‚îÇ         ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ         ‚îÇ                      ‚îÇ                         ‚îÇ
‚îÇ         ‚ñº                      ‚ñº                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ  Approved?                                     ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ    ‚îú‚îÄ‚îÄ YES ‚Üí Sign-off (Pronto para merge)    ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ    ‚îî‚îÄ‚îÄ NO ‚Üí Re-validar              ‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                        ‚îÇ                                     ‚îÇ
‚îÇ                        ‚ñº                                     ‚îÇ
‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
‚îÇ              ‚îÇ  Max Iterations?        ‚îÇ                ‚îÇ
‚îÇ              ‚îÇ    ‚îî‚îÄ‚îÄ YES ‚Üí Escalate          ‚îÇ                ‚îÇ
‚îÇ              ‚îÇ       (Human Review)        ‚îÇ                ‚îÇ
‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 2. Componentes Principais

### 2.1 QA Loop Orchestrator (`qa/loop.py`)

**Responsabilidades:**
- Coordenar loop de itera√ß√µes (max: 50)
- Gerenciar estados de QA (pending, in_progress, approved, rejected)
- Controlar consecutive errors (max: 3)
- Emitir eventos de fase (QA_REVIEW, QA_FIXING, COMPLETE, FAILED)
- Integrar com Linear (opcional)

**Fun√ß√µes Principais:**

```python
async def run_qa_validation_loop(
    project_dir: Path,
    spec_dir: Path,
    model: str,
    verbose: bool = False,
) -> bool:
    """
    Loop principal de QA.

    Retorna: True se aprovado, False caso contr√°rio
    """
    # 1. Verifica se build est√° completa
    # 2. Processa feedback humano (se existir)
    # 3. Detecta projetos sem testes
    # 4. Inicia loop de itera√ß√µes
    #    4.1. Executa QA Reviewer
    #    4.2. Se rejeitado ‚Üí Executa QA Fixer
    #    4.3. Detecta issues recorrentes
    #    4.4. Escalona se necess√°rio
    #    4.5. Se aprovado ‚Üí Sign-off
    # 5. Atualiza Linear (se habilitado)
```

**Constants de Configura√ß√£o:**
- `MAX_QA_ITERATIONS = 50` - M√°ximo de itera√ß√µes
- `MAX_CONSECUTIVE_ERRORS = 3` - Erros consecutivos sem progresso

---

### 2.2 QA Reviewer Agent (`qa/reviewer.py`)

**Responsabilidades:**
- Carregar contexto de mem√≥ria (Graphiti)
- Validar acceptance criteria completas
- Executar testes automatizados (unit, integration, E2E)
- Verificar seguran√ßa, padr√µes, regress√µes
- Gerar relat√≥rio de QA (`qa_report.md`)
- Atualizar `implementation_plan.json` com status

**Fun√ß√µes Principais:**

```python
async def run_qa_agent_session(
    client: ClaudeSDKClient,
    project_dir: Path,
    spec_dir: Path,
    qa_session: int,
    max_iterations: int,
    verbose: bool = False,
    previous_error: dict | None = None,  # Para auto-corre√ß√£o
) -> tuple[str, str]:
    """
    Executa sess√£o de QA reviewer.

    Retorna: (status, response_text)
    - status: "approved", "rejected", ou "error"
    - response_text: Conte√∫do da resposta do agente
    """
    # 1. Carrega prompt com tools din√¢micos (Electron, Puppeteer, etc)
    # 2. Recupera contexto de mem√≥ria (Graphiti)
    # 3. Executa query com Claude SDK
    # 4. Stream resposta em tempo real
    # 5. Verifica se implement_plan.json foi atualizado
    # 6. Salva descobertas na mem√≥ria
```

**Prompt Estrutura (`prompts/qa_reviewer.md`):**

```
## PHASE 0: LOAD CONTEXT (MANDATORY)
- spec.md
- implementation_plan.json
- project_index.json
- build-progress.txt
- git diff
- acceptance criteria

## PHASE 1: VERIFY ALL SUBTASKS COMPLETED
- Contagem de subtasks: completed/pending/in_progress

## PHASE 2: START DEVELOPMENT ENVIRONMENT
- Inicia servi√ßos (init.sh)
- Verifica healthy status

## PHASE 3: RUN AUTOMATED TESTS
### 3.1: Unit Tests
- Executa unit tests para servi√ßos afetados
- Documenta resultados: PASS/FAIL (X/Y)

### 3.2: Integration Tests
- Executa testes de integra√ß√£o entre servi√ßos
- Documenta resultados: PASS/FAIL (X/Y)

### 3.3: End-to-End Tests
- Executa E2E tests (Playwright, Cypress, etc.)
- Usa browser automation
- Documenta resultados: PASS/FAIL (X/Y)

## PHASE 4: BROWSER VERIFICATION (Se Frontend)
### 4.1: Navigate and Screenshot
- Navega para URL
- Tira screenshot
- Verifica visual elements
- Testa intera√ß√µes

### 4.2: Console Error Check
- Verifica erros JavaScript
- Verifica warnings
- Verifica network requests falhadas

## PHASE 5: DATABASE VERIFICATION (Se Aplic√°vel)
### 5.1: Check Migrations
- Verifica se migrations existem e foram aplicadas

### 5.2: Verify Schema
- Verifica schema do banco de dados

## PHASE 6: CODE REVIEW
### 6.0: Third-Party API/Library Validation (Use Context7)
- Valida uso de bibliotecas contra docs oficiais
- Verifica assinaturas de fun√ß√µes
- Verifica patterns de inicializa√ß√£o

### 6.1: Security Review
- Busca vulnerabilidades comuns (eval, innerHTML, exec, shell)
- Busca secrets hardcoded (password, api_key, token)

### 6.2: Pattern Compliance
- Verifica compliance com padr√µes estabelecidos

## PHASE 7: REGRESSION CHECK
### 7.1: Run Full Test Suite
- Executa TODOS os testes, n√£o apenas novos

### 7.2: Check Key Existing Functionality
- Verifica que features existentes n√£o foram quebradas

## PHASE 8: GENERATE QA REPORT
- Tabela resumo por categoria
- Lista de issues encontradas (Critical, Major, Minor)
- Recommended fixes

## PHASE 9: UPDATE IMPLEMENTATION PLAN
### Se APROVADO:
```json
{
  "qa_signoff": {
    "status": "approved",
    "timestamp": "[ISO timestamp]",
    "qa_session": [session-number],
    "report_file": "qa_report.md",
    "tests_passed": {
      "unit": "X/Y",
      "integration": "X/Y",
      "e2e": "X/Y"
    },
    "verified_by": "qa_agent"
  }
}
```

### Se REJEITADO:
```json
{
  "qa_signoff": {
    "status": "rejected",
    "timestamp": "[ISO timestamp]",
    "qa_session": [session-number],
    "issues_found": [
      {
        "type": "critical",
        "title": "[issue]",
        "location": "[file:line]",
        "fix_required": "[description]"
      }
    ],
    "fix_request_file": "QA_FIX_REQUEST.md"
  }
}
```
```

---

### 2.3 QA Fixer Agent (`qa/fixer.py`)

**Responsabilidades:**
- Ler `QA_FIX_REQUEST.md` (issues a corrigir)
- Aplicar fixes uma por uma
- Verificar cada fix localmente
- Executar testes ap√≥s cada fix
- Atualizar `implementation_plan.json` com status `fixes_applied`
- N√£o introduzir novos bugs

**Fun√ß√µes Principais:**

```python
async def run_qa_fixer_session(
    client: ClaudeSDKClient,
    spec_dir: Path,
    fix_session: int,
    verbose: bool = False,
    project_dir: Path | None = None,
) -> tuple[str, str]:
    """
    Executa sess√£o de QA fixer.

    Retorna: (status, response_text)
    - status: "fixed" ou "error"
    - response_text: Conte√∫do da resposta
    """
    # 1. Verifica que QA_FIX_REQUEST.md existe
    # 2. Carrega prompt do fixer
    # 3. Recupera contexto de mem√≥ria (Graphiti)
    # 4. Executa query com Claude SDK
    # 5. Aplica fixes uma por uma
    # 6. Verifica cada fix
    # 7. Atualiza implementation_plan.json
```

**Prompt Estrutura (`prompts/qa_fixer.md`):**

```
## PHASE 0: LOAD CONTEXT (MANDATORY)
- QA_FIX_REQUEST.md (issues a corrigir)
- qa_report.md (contexto completo dos issues)
- spec.md (requisitos)
- implementation_plan.json (qa_signoff status)

## PHASE 1: PARSE FIX REQUIREMENTS
- Extrai lista de issues de QA_FIX_REQUEST.md
- Para cada issue: t√≠tulo, localiza√ß√£o, problema, fix esperado

## PHASE 2: START DEVELOPMENT ENVIRONMENT
- Inicia servi√ßos se necess√°rio

## üö® CRITICAL: PATH CONFUSION PREVENTION üö®
- O agente SEMPRE deve verificar cwd antes de comandos
- Usa caminhos relativos se estiver em subdiret√≥rio
- Verifica que arquivos existem antes de operar

## PHASE 3: FIX ISSUES ONE BY ONE
- Para cada issue:
  1. Ler arquivo/√°rea do problema
  2. Entender o que est√° errado
  3. Implementar fix m√≠nimo necess√°rio
  4. N√£o refatorar c√≥digo ao redor
  5. N√£o adicionar features
  6. Testar fix localmente

## PHASE 4: RUN TESTS
- Executa full test suite ap√≥s todos os fixes
- Executa testes espec√≠ficos que falharam

## PHASE 5: SELF-VERIFICATION
- Verifica cada fix da QA_FIX_REQUEST.md
- Confirma que issue foi resolvido

## PHASE 6: COMMIT FIXES
- Atualiza implementation_plan.json:
```json
{
  "qa_signoff": {
    "status": "fixes_applied",
    "timestamp": "[ISO timestamp]",
    "fix_session": [session-number],
    "issues_fixed": [
      {
        "title": "[issue title]",
        "fix_commit": "[commit hash]"
      }
    ],
    "ready_for_qa_revalidation": true
  }
}
```

## COMMON FIX PATTERNS
- Missing Migration
- Failing Test
- Console Error
- Security Issue
- Pattern Violation
```

---

### 2.4 Criteria & Status Management (`qa/criteria.py`)

**Responsabilidades:**
- Gerenciar acceptance criteria
- Ler/escrever `implementation_plan.json`
- Determinar se QA deve rodar
- Verificar status atual (approved/rejected/fixes_applied)

**Fun√ß√µes Principais:**

```python
# Status Checks
def is_qa_approved(spec_dir: Path) -> bool:
    """QA aprovou build?"""
    return qa_signoff.get("status") == "approved"

def is_qa_rejected(spec_dir: Path) -> bool:
    """QA rejeitou build (precisa de fixes)?"""
    return qa_signoff.get("status") == "rejected"

def is_fixes_applied(spec_dir: Path) -> bool:
    """Fixes foram aplicados e pronto para re-valida√ß√£o?"""
    return qa_signoff.get("status") == "fixes_applied"

# Readiness Checks
def should_run_qa(spec_dir: Path) -> bool:
    """QA deve rodar?"""
    return is_build_complete(spec_dir) and not is_qa_approved(spec_dir)

def should_run_fixes(spec_dir: Path) -> bool:
    """QA fixer deve rodar?"""
    return is_qa_rejected(spec_dir) and iterations < MAX_QA_ITERATIONS

# Iteration Counting
def get_qa_iteration_count(spec_dir: Path) -> int:
    """Quantas itera√ß√µes de QA j√° rodaram?"""
    return qa_signoff.get("qa_session", 0)

# Status Display
def print_qa_status(spec_dir: Path) -> None:
    """Imprime status atual de QA"""
```

---

### 2.5 Report & Issue Tracking (`qa/report.py`)

**Responsabilidades:**
- Rastrear hist√≥rico de itera√ß√µes
- Detectar issues recorrentes (3+ ocorr√™ncias)
- Calcular similaridade entre issues (threshold: 0.8)
- Criar relat√≥rios de escalonamento (`QA_ESCALATION.md`)
- Criar planos de teste manual (`MANUAL_TEST_PLAN.md`)

**Fun√ß√µes Principais:**

```python
# Iteration History
def get_iteration_history(spec_dir: Path) -> list[dict]:
    """Retorna hist√≥rico completo de itera√ß√µes"""

def record_iteration(
    spec_dir: Path,
    iteration: int,
    status: str,  # "approved", "rejected", "error"
    issues: list[dict],
    duration_seconds: float | None = None,
) -> bool:
    """Registra itera√ß√£o no hist√≥rico"""

# Recurring Issue Detection
def has_recurring_issues(
    current_issues: list[dict],
    history: list[dict],
    threshold: int = 3,
) -> tuple[bool, list[dict]]:
    """
    Detecta issues que aparecem 3+ vezes.

    Usa SequenceMatcher para similaridade (threshold: 0.8)
    """

def _normalize_issue_key(issue: dict) -> str:
    """
    Cria chave normalizada: "titulo|arquivo|linha"

    Remove prefixos comuns: "error:", "issue:", "bug:", "fix:"
    """

def _issue_similarity(issue1: dict, issue2: dict) -> float:
    """
    Calcula similaridade entre dois issues.

    Combina t√≠tulo + localiza√ß√£o.
    Retorna score 0.0-1.0.
    """

def get_recurring_issue_summary(history: list[dict]) -> dict:
    """
    Analisa hist√≥rico para issues mais comuns.

    Retorna:
    - total_issues: Total de issues encontradas
    - unique_issues: Issues √∫nicas
    - most_common: Top 5 issues mais comuns
    - iterations_approved/rejected
    - fix_success_rate
    """

# Escalation
async def escalate_to_human(
    spec_dir: Path,
    recurring_issues: list[dict],
    iteration: int,
) -> None:
    """
    Cria QA_ESCALATION.md quando issues recorrem.
    """

# No-Test Project
def is_no_test_project(spec_dir: Path, project_dir: Path) -> bool:
    """
    Detecta se projeto N√ÉO tem infraestrutura de testes.

    Se true, cria MANUAL_TEST_PLAN.md.
    """

def create_manual_test_plan(spec_dir: Path, spec_name: str) -> Path:
    """
    Cria plano de teste manual quando sem automa√ß√£o.
    """
```

---

### 2.6 Acceptance Criteria (Definidos em spec.md)

Exemplo de crit√©rios de aceita√ß√£o em spec:

```markdown
## QA Acceptance Criteria

### 1. Core Functionality
- [ ] Feature works as described in spec
- [ ] All edge cases handled
- [ ] Error states display appropriate messages

### 2. Testing
- [ ] Unit tests pass (80%+ coverage)
- [ ] Integration tests pass
- [ ] E2E tests pass (for UI projects)

### 3. Code Quality
- [ ] No console errors
- [ ] No warnings
- [ ] Follows project patterns
- [ ] No hardcoded secrets

### 4. Security
- [ ] Input sanitization implemented
- [ ] No SQL injection vulnerabilities
- [ ] No XSS vulnerabilities
- [ ] Authentication/authorization correct

### 5. Performance
- [ ] Response time < 500ms (for APIs)
- [ ] No excessive memory usage
- [ ] No memory leaks

### 6. Documentation
- [ ] API documented (OpenAPI/Swagger)
- [ ] README updated
- [ ] Inline code comments for complex logic
```

---

### 2.7 Memory Integration (Graphiti)

**Responsabilidades:**
- Recuperar contexto de sess√µes anteriores
- Salvar descobertas de QA (patterns, gotchas, issues)
- Indexar por embeddings (busca sem√¢ntica)
- Disponibilizar para pr√≥ximas sess√µes

**Fun√ß√µes (em `agents/memory_manager.py`):**

```python
async def get_graphiti_context(
    spec_dir: Path,
    project_dir: Path,
    context_request: dict,
) -> str:
    """
    Recupera contexto de Graphiti para sess√£o.

    Retorna: String com contexto relevante
    """

async def save_session_memory(
    spec_dir: Path,
    project_dir: Path,
    subtask_id: str,
    session_num: int,
    success: bool,
    subtasks_completed: list[str],
    discoveries: dict,
) -> bool:
    """
    Salva mem√≥ria da sess√£o no Graphiti.

    discoveries: {
      "files_understood": {},
      "patterns_found": ["Pattern 1", "Pattern 2"],
      "gotchas_encountered": ["Gotcha 1", "Gotcha 2"]
    }
    """
```

**Tipos de Descobertas Salvas:**
- **Patterns**: Padr√µes de c√≥digo e arquitetura
- **Gotchas**: Armadilhas e pitfalls encontrados
- **Files Understood**: Arquivos lidos e compreendidos

---

### 2.8 E2E Testing (Electron MCP)

**Habilitado quando:**
- `ELECTRON_MCP_ENABLED=true` no `.env`
- Projeto detectado como Electron

**Ferramentas Dispon√≠veis (injetadas automaticamente no prompt):**

```
# MCP: Electron (para apps Electron)
mcp__electron__get_electron_window_info
mcp__electron__take_screenshot
mcp__electron__send_command_to_electron

Comandos dispon√≠veis via send_command_to_electron:
- click_by_text - Clica bot√£o por texto vis√≠vel
- click_by_selector - Clica elemento por CSS selector
- fill_input - Preenche campo (placeholder ou selector)
- select_option - Seleciona dropdown
- send_keyboard_shortcut - Envia atalho (Enter, Ctrl+N, etc)
- navigate_to_hash - Navega para rota (#settings, #create)
- get_page_structure - Estrutura organizada da p√°gina
- verify_form_state - Verifica estado de formul√°rio
- eval - Executa JavaScript arbitr√°rio
```

**Fluxo E2E T√≠pico:**

```python
# 1. QA toma screenshot
agent: "Take a screenshot to see the current UI"
# Usa: mcp__electron__take_screenshot

# 2. QA inspeciona p√°gina
agent: "Get page structure to find available buttons"
# Usa: mcp__electron__send_command_to_electron (command: "get_page_structure")

# 3. QA clica bot√£o
agent: "Click the 'Create New Spec' button"
# Usa: mcp__electron__send_command_to_electron (
#      command: "click_by_text",
#      args: {"text": "Create New Spec"}
# )

# 4. QA preenche formul√°rio
agent: "Fill the task description field"
# Usa: mcp__electron__send_command_to_electron (
#      command: "fill_input",
#      args: {"placeholder": "Describe your task", "value": "Add login feature"}
# )

# 5. QA submete e verifica
agent: "Click Submit and verify success"
# Usa: click_by_text + take_screenshot
```

---

## 3. Fluxo Completo de Execu√ß√£o

### 3.1 Inicializa√ß√£o

```
1. Coder Agent completa todos subtasks
2. Build marked as "complete"
3. QA Loop iniciado automaticamente
4. Verifica se j√° aprovado (skip se sim)
5. Verifica feedback humano (QA_FIX_REQUEST.md)
```

### 3.2 Itera√ß√£o de QA

```
Itera√ß√£o N:
‚îú‚îÄ‚îÄ 1. Carregar contexto
‚îÇ    ‚îú‚îÄ‚îÄ spec.md
‚îÇ    ‚îú‚îÄ‚îÄ implementation_plan.json
‚îÇ    ‚îú‚îÄ‚îÄ project_index.json
‚îÇ    ‚îú‚îÄ‚îÄ Graphiti memory (patterns, gotchas)
‚îÇ    ‚îî‚îÄ‚îÄ previous_error (se falhou antes)
‚îÇ
‚îú‚îÄ‚îÄ 2. Executar QA Reviewer
‚îÇ    ‚îú‚îÄ‚îÄ Phase 0: Load Context
‚îÇ    ‚îú‚îÄ‚îÄ Phase 1: Verify subtasks
‚îÇ    ‚îú‚îÄ‚îÄ Phase 2: Start services
‚îÇ    ‚îú‚îÄ‚îÄ Phase 3: Run tests
‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ Unit tests
‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ Integration tests
‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ E2E tests (Electron MCP)
‚îÇ    ‚îú‚îÄ‚îÄ Phase 4: Browser verification (se aplic√°vel)
‚îÇ    ‚îú‚îÄ‚îÄ Phase 5: Database verification (se aplic√°vel)
‚îÇ    ‚îú‚îÄ‚îÄ Phase 6: Code review
‚îÇ    ‚îú‚îÄ‚îÄ Phase 7: Regression check
‚îÇ    ‚îú‚îÄ‚îÄ Phase 8: Generate QA report
‚îÇ    ‚îî‚îÄ‚îÄ Phase 9: Update implementation_plan.json
‚îÇ
‚îú‚îÄ‚îÄ 3. Checar resultado
‚îÇ    ‚îú‚îÄ‚îÄ Se approved ‚Üí Sign-off (termina)
‚îÇ    ‚îú‚îÄ‚îÄ Se rejected ‚Üí Ir para QA Fixer
‚îÇ    ‚îî‚îÄ‚îÄ Se error ‚Üí Auto-corre√ß√£o na pr√≥xima itera√ß√£o
‚îÇ
‚îî‚îÄ‚îÄ 4. Detectar issues recorrentes
     ‚îú‚îÄ‚îÄ Se 3+ ocorr√™ncias ‚Üí Escalonar para humano
     ‚îî‚îÄ‚îÄ Criar QA_ESCALATION.md
```

### 3.3 Itera√ß√£o de Fixer

```
Se QA rejeitou:
‚îú‚îÄ‚îÄ 1. Carregar contexto
‚îÇ    ‚îú‚îÄ‚îÄ QA_FIX_REQUEST.md (issues a corrigir)
‚îÇ    ‚îú‚îÄ‚îÄ qa_report.md (detalhes dos issues)
‚îÇ    ‚îú‚îÄ‚îÄ spec.md (requisitos)
‚îÇ    ‚îî‚îÄ‚îÄ Graphiti memory (fixes anteriores)
‚îÇ
‚îú‚îÄ‚îÄ 2. Executar QA Fixer
‚îÇ    ‚îú‚îÄ‚îÄ Phase 0: Load Context
‚îÇ    ‚îú‚îÄ‚îÄ Phase 1: Parse fix requirements
‚îÇ    ‚îú‚îÄ‚îÄ Phase 2: Start services
‚îÇ    ‚îú‚îÄ‚îÄ Phase 3: Fix issues one by one
‚îÇ    ‚îú‚îÄ‚îÄ Phase 4: Run tests
‚îÇ    ‚îú‚îÄ‚îÄ Phase 5: Self-verification
‚îÇ    ‚îú‚îÄ‚îÄ Phase 6: Commit fixes
‚îÇ    ‚îî‚îÄ‚îÄ Phase 7: Update implementation_plan.json
‚îÇ
‚îî‚îÄ‚îÄ 3. Loop volta para QA Reviewer
```

### 3.4 Escalonamento

```
Crit√©rios de Escalonamento:
‚îú‚îÄ‚îÄ 3+ ocorr√™ncias do mesmo issue (similarity >= 0.8)
‚îú‚îÄ‚îÄ Max itera√ß√µes atingida (50)
‚îî‚îÄ‚îÄ Erros consecutivos sem progresso (3)

A√ß√µes ao Escalonar:
‚îú‚îÄ‚îÄ Criar QA_ESCALATION.md com:
‚îÇ    ‚îú‚îÄ‚îÄ Lista de issues recorrentes
‚îÇ    ‚îú‚îÄ‚îÄ Contagem de itera√ß√µes
‚îÇ    ‚îú‚îÄ‚îÄ Taxa de sucesso de fixes
‚îÇ    ‚îî‚îÄ‚îÄ Issues mais comuns (top 5)
‚îÇ
‚îú‚îÄ‚îÄ Atualizar Linear (se habilitado):
‚îÇ    ‚îú‚îÄ‚îÄ "QA max iterations reached"
‚îÇ    ‚îî‚îÄ‚îÄ "Needs human intervention"
‚îÇ
‚îî‚îÄ‚îÄ Terminar QA loop com status "failed"
```

---

## 4. Estrutura de Arquivos

### 4.1 Diret√≥rio de Spec

```
.auto-claude/specs/XXX-feature/
‚îú‚îÄ‚îÄ spec.md                          # Especifica√ß√£o original
‚îú‚îÄ‚îÄ implementation_plan.json            # Plano de implementa√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ phases: [...]
‚îÇ   ‚îú‚îÄ‚îÄ qa_signoff: {
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ status: "approved" | "rejected" | "fixes_applied"
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ timestamp: "2026-01-14T..."
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ qa_session: 5
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tests_passed: {unit, integration, e2e}
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ issues_found: [...]
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ report_file: "qa_report.md"
‚îÇ   ‚îú‚îÄ‚îÄ qa_iteration_history: [...]     # Hist√≥rico completo
‚îÇ   ‚îî‚îÄ‚îÄ qa_stats: {
‚îÇ       ‚îú‚îÄ‚îÄ total_iterations: 5
‚îÇ       ‚îú‚îÄ‚îÄ last_iteration: 5
‚îÇ       ‚îú‚îÄ‚îÄ last_status: "approved"
‚îÇ       ‚îî‚îÄ‚îÄ issues_by_type: {critical: 2, major: 3, minor: 5}
‚îú‚îÄ‚îÄ qa_report.md                   # Relat√≥rio de QA
‚îú‚îÄ‚îÄ QA_FIX_REQUEST.md              # Issues para corrigir (se rejeitado)
‚îú‚îÄ‚îÄ QA_ESCALATION.md              # Escalonamento (se recorrente)
‚îî‚îÄ‚îÄ MANUAL_TEST_PLAN.md            # Plano manual (sem testes)
```

---

## 5. Integra√ß√µes Externas

### 5.1 Linear (Opcional)

**Fun√ß√µes (`linear_updater.py`):**

```python
# Estados de Linear
async def linear_qa_started(spec_dir: Path):
    """Move task para "In Review" no Linear"""

async def linear_qa_approved(spec_dir: Path):
    """Move task para "QA Approved, Awaiting Human Review" no Linear"""

async def linear_qa_rejected(spec_dir: Path, issues_count: int, iteration: int):
    """Move task para "Rejected" no Linear com contagem de issues"""

async def linear_qa_max_iterations(spec_dir: Path, iteration: int):
    """Move task para "Needs Human Intervention (Recurring Issues)" no Linear"""

class LinearTaskState:
    """Classe para carregar/linear-task.json"""
    task_id: str
    state: str
    last_updated: str
```

---

## 6. Diferen√ßas para Skybridge

### 6.1 O que Skybridge J√Å TEM

| Componente | Auto-Claude | Skybridge | Gap |
|------------|-------------|-----------|------|
| **Worktree Management** | ‚úÖ Sim | ‚úÖ Sim | Nenhuma |
| **Snapshot Captura** | ‚úÖ Sim (n√£o integrado) | ‚úÖ Sim (GitExtractor) | Skybridge mais robusto |
| **Job Queue** | ‚úÖ Sim | ‚úÖ Sim | Similar |
| **Agent Framework** | ‚úÖ Sim (SDK) | ‚úÖ Sim (ClaudeCodeAdapter) | Similar |
| **Memory** | ‚úÖ Graphiti | ‚ùå N√£o | Completo |

---

### 6.2 O que Skybridge N√ÉO TEM (GAP)

| Componente | Auto-Claude | Skybridge | Gap |
|------------|-------------|-----------|------|
| **QA Loop** | ‚úÖ Completo | ‚ùå N√£o | CR√çTICO |
| **QA Reviewer Agent** | ‚úÖ Sim | ‚ùå N√£o | CR√çTICO |
| **QA Fixer Agent** | ‚úÖ Sim | ‚ùå N√£o | CR√çTICO |
| **Criteria Management** | ‚úÖ Sim | ‚ùå N√£o | ALTO |
| **Iteration History** | ‚úÖ Sim | ‚ùå N√£o | ALTO |
| **Recurring Issues Detection** | ‚úÖ Sim | ‚ùå N√£o | ALTO |
| **Escalation Logic** | ‚úÖ Sim | ‚ùå N√£o | ALTO |
| **E2E Testing** | ‚úÖ Electron MCP | ‚ùå N√£o | M√âDIO |
| **Memory Integration** | ‚úÖ Graphiti | ‚ùå N√£o | M√âDIO |
| **Linear Integration** | ‚úÖ Sim | ‚ùå N√£o | BAIXO |
| **No-Test Handling** | ‚úÖ Sim | ‚ùå N√£o | BAIXO |
| **Manual Test Plans** | ‚úÖ Sim | ‚ùå N√£o | BAIXO |

---

## 7. Guia de Implementa√ß√£o - Skybridge

### 7.1 Estrutura Sugerida

```
src/skybridge/core/contexts/qa/
‚îú‚îÄ‚îÄ __init__.py                    # Export p√∫blico
‚îú‚îÄ‚îÄ loop.py                        # Orquestrador principal
‚îú‚îÄ‚îÄ reviewer.py                    # Agente QA reviewer
‚îú‚îÄ‚îÄ fixer.py                      # Agente QA fixer
‚îú‚îÄ‚îÄ criteria.py                   # Gerenciamento de crit√©rios
‚îú‚îÄ‚îÄ report.py                     # Rastreamento e relat√≥rios
‚îî‚îÄ‚îÄ prompts/
    ‚îú‚îÄ‚îÄ qa_reviewer.md            # Prompt do reviewer
    ‚îî‚îÄ‚îÄ qa_fixer.md              # Prompt do fixer

src/skybridge/core/contexts/validation/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ acceptance_criteria.py        # Defini√ß√£o de crit√©rios
‚îî‚îÄ‚îÄ test_runner.py             # Runner de testes (unit, integration)
```

---

### 7.2 Arquitetura de Componentes

#### 7.2.1 QA Loop Orchestrator (`qa/loop.py`)

```python
"""
QA Validation Loop - Skybridge Adaptation
=====================================

Orquestra valida√ß√£o de QA at√© aprova√ß√£o ou limite.
"""

from pathlib import Path
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from skybridge.core.contexts.webhooks.ports.job_queue_port import JobQueuePort
    from skybridge.core.contexts.webhooks.domain.webhook_job import WebhookJob

from skybridge.kernel.contracts.result import Result
from skybridge.platform.observability.logger import get_logger


# Configura√ß√£o
MAX_QA_ITERATIONS = 50
MAX_CONSECUTIVE_ERRORS = 3


class QALoopOrchestrator:
    """
    Orquestrador do QA Loop.

    Responsabilidades:
    - Coordenar itera√ß√µes de QA
    - Gerenciar reviewer e fixer
    - Rastrear hist√≥rico
    - Detectar issues recorrentes
    - Escalonar para humanos
    """

    def __init__(
        self,
        job_queue: "JobQueuePort",
        agent_adapter,  # ClaudeCodeAdapter
        project_dir: Path,
    ):
        self.job_queue = job_queue
        self.agent_adapter = agent_adapter
        self.project_dir = project_dir
        self.logger = get_logger()

    async def run_qa_validation_loop(
        self,
        spec_dir: Path,
        job: WebhookJob,
        model: str = "sonnet",
        max_iterations: int = MAX_QA_ITERATIONS,
    ) -> Result[bool, str]:
        """
        Executa loop completo de QA.

        Retorna: Result com sucesso/fracasso e mensagem
        """
        # 1. Verificar se build est√° completa
        # 2. Iniciar itera√ß√µes
        # 3. Para cada itera√ß√£o:
        #    3.1. Executar QA Reviewer
        #    3.2. Se approved ‚Üí sign-off
        #    3.3. Se rejected ‚Üí QA Fixer
        #    3.4. Se error ‚Üí auto-corre√ß√£o
        #    3.5. Detectar issues recorrentes
        # 4. Escalonar se necess√°rio

        pass  # Implementa√ß√£o detalhada abaixo

    async def _run_qa_reviewer(
        self,
        spec_dir: Path,
        iteration: int,
        job: WebhookJob,
        previous_error: dict | None = None,
    ) -> Result[bool, str]:
        """
        Executa agente QA reviewer.
        """
        pass

    async def _run_qa_fixer(
        self,
        spec_dir: Path,
        iteration: int,
        job: WebhookJob,
    ) -> Result[bool, str]:
        """
        Executa agente QA fixer.
        """
        pass

    def _should_escalate(
        self,
        current_issues: list[dict],
        history: list[dict],
    ) -> tuple[bool, list[dict]]:
        """
        Verifica se deve escalonar (3+ ocorr√™ncias).
        """
        pass

    async def _escalate_to_human(
        self,
        spec_dir: Path,
        recurring_issues: list[dict],
        iteration: int,
    ) -> None:
        """
        Cria arquivo de escalonamento.
        """
        pass
```

---

#### 7.2.2 QA Reviewer Agent (`qa/reviewer.py`)

```python
"""
QA Reviewer Agent - Skybridge Adaptation
======================================

Valida implementa√ß√£o contra acceptance criteria.
"""

from pathlib import Path
from skybridge.core.client import create_client  # Ajustar conforme Skybridge
from skybridge.kernel.contracts.result import Result


async def run_qa_reviewer_session(
    client,  # ClaudeSDKClient
    project_dir: Path,
    spec_dir: Path,
    qa_session: int,
    max_iterations: int,
    verbose: bool = False,
    previous_error: dict | None = None,
) -> tuple[str, str]:
    """
    Executa sess√£o de QA reviewer.

    Retorna: (status, response_text)
    - status: "approved", "rejected", ou "error"
    """
    # 1. Carregar prompt (qa_reviewer.md)
    # 2. Carregar contexto de mem√≥ria (se dispon√≠vel)
    # 3. Executar query com cliente
    # 4. Stream resposta
    # 5. Verificar se qa_signoff foi atualizado
    # 6. Retornar status

    pass
```

---

#### 7.2.3 QA Fixer Agent (`qa/fixer.py`)

```python
"""
QA Fixer Agent - Skybridge Adaptation
===================================

Corrige issues encontradas pelo QA reviewer.
"""

from pathlib import Path
from skybridge.core.client import create_client
from skybridge.kernel.contracts.result import Result


async def run_qa_fixer_session(
    client,
    spec_dir: Path,
    fix_session: int,
    verbose: bool = False,
    project_dir: Path | None = None,
) -> tuple[str, str]:
    """
    Executa sess√£o de QA fixer.

    Retorna: (status, response_text)
    - status: "fixed" ou "error"
    """
    # 1. Verificar QA_FIX_REQUEST.md
    # 2. Carregar prompt (qa_fixer.md)
    # 3. Executar query com cliente
    # 4. Aplicar fixes
    # 5. Testar cada fix
    # 6. Atualizar qa_signoff (fixes_applied)

    pass
```

---

#### 7.2.4 Criteria Management (`qa/criteria.py`)

```python
"""
QA Acceptance Criteria - Skybridge Adaptation
==========================================

Gerencia acceptance criteria e status de QA.
"""

import json
from pathlib import Path
from skybridge.kernel.contracts.result import Result


# Implementa√ß√£o Plan I/O
def load_implementation_plan(spec_dir: Path) -> dict | None:
    """Carrega implementation_plan.json"""
    plan_file = spec_dir / "implementation_plan.json"
    if not plan_file.exists():
        return None
    try:
        with open(plan_file) as f:
            return json.load(f)
    except (OSError, json.JSONDecodeError):
        return None


def save_implementation_plan(spec_dir: Path, plan: dict) -> Result[None, str]:
    """Salva implementation_plan.json"""
    plan_file = spec_dir / "implementation_plan.json"
    try:
        with open(plan_file, "w") as f:
            json.dump(plan, f, indent=2)
        return Result.ok(None)
    except OSError as e:
        return Result.err(f"Failed to save: {str(e)}")


# QA Sign-off Status
def get_qa_signoff_status(spec_dir: Path) -> dict | None:
    """Retorna status atual de QA sign-off"""
    plan = load_implementation_plan(spec_dir)
    if not plan:
        return None
    return plan.get("qa_signoff")


def is_qa_approved(spec_dir: Path) -> bool:
    """QA aprovou build?"""
    status = get_qa_signoff_status(spec_dir)
    if not status:
        return False
    return status.get("status") == "approved"


def is_qa_rejected(spec_dir: Path) -> bool:
    """QA rejeitou build (precisa de fixes)?"""
    status = get_qa_signoff_status(spec_dir)
    if not status:
        return False
    return status.get("status") == "rejected"


def is_fixes_applied(spec_dir: Path) -> bool:
    """Fixes foram aplicados?"""
    status = get_qa_signoff_status(spec_dir)
    if not status:
        return False
    return status.get("status") == "fixes_applied"


def get_qa_iteration_count(spec_dir: Path) -> int:
    """Contagem de itera√ß√µes de QA"""
    status = get_qa_signoff_status(spec_dir)
    if not status:
        return 0
    return status.get("qa_session", 0)


# Readiness Checks
def should_run_qa(spec_dir: Path) -> bool:
    """QA deve rodar?"""
    # Verificar se build est√° completa (usar l√≥gica do job)
    # Verificar se ainda n√£o aprovou
    return True  # Placeholder


def should_run_fixes(spec_dir: Path) -> bool:
    """QA fixer deve rodar?"""
    return is_qa_rejected(spec_dir) and get_qa_iteration_count(spec_dir) < MAX_QA_ITERATIONS
```

---

#### 7.2.5 Report & Issue Tracking (`qa/report.py`)

```python
"""
QA Report & Issue Tracking - Skybridge Adaptation
=============================================

Rastreamento de itera√ß√µes e detec√ß√£o de issues recorrentes.
"""

from pathlib import Path
from datetime import datetime, timezone
from difflib import SequenceMatcher
from collections import Counter
from skybridge.kernel.contracts.result import Result


# Configura√ß√£o
RECURRING_ISSUE_THRESHOLD = 3
ISSUE_SIMILARITY_THRESHOLD = 0.8


def get_iteration_history(spec_dir: Path) -> list[dict]:
    """Retorna hist√≥rico de itera√ß√µes"""
    plan = load_implementation_plan(spec_dir)
    if not plan:
        return []
    return plan.get("qa_iteration_history", [])


def record_iteration(
    spec_dir: Path,
    iteration: int,
    status: str,
    issues: list[dict],
    duration_seconds: float | None = None,
) -> Result[None, str]:
    """Registra itera√ß√£o no hist√≥rico"""
    plan = load_implementation_plan(spec_dir)
    if not plan:
        plan = {}

    if "qa_iteration_history" not in plan:
        plan["qa_iteration_history"] = []

    record = {
        "iteration": iteration,
        "status": status,
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "issues": issues,
    }

    if duration_seconds is not None:
        record["duration_seconds"] = round(duration_seconds, 2)

    plan["qa_iteration_history"].append(record)

    # Atualizar stats
    if "qa_stats" not in plan:
        plan["qa_stats"] = {}

    plan["qa_stats"]["total_iterations"] = len(plan["qa_iteration_history"])
    plan["qa_stats"]["last_iteration"] = iteration
    plan["qa_stats"]["last_status"] = status

    # Salvar
    result = save_implementation_plan(spec_dir, plan)
    return result


def _normalize_issue_key(issue: dict) -> str:
    """Normaliza chave de issue"""
    title = (issue.get("title") or "").lower().strip()
    file = (issue.get("file") or "").lower().strip()
    line = issue.get("line") or ""

    for prefix in ["error:", "issue:", "bug:", "fix:"]:
        if title.startswith(prefix):
            title = title[len(prefix):].strip()

    return f"{title}|{file}|{line}"


def _issue_similarity(issue1: dict, issue2: dict) -> float:
    """Calcula similaridade entre issues"""
    key1 = _normalize_issue_key(issue1)
    key2 = _normalize_issue_key(issue2)

    return SequenceMatcher(None, key1, key2).ratio()


def has_recurring_issues(
    current_issues: list[dict],
    history: list[dict],
    threshold: int = RECURRING_ISSUE_THRESHOLD,
) -> tuple[bool, list[dict]]:
    """Detecta issues recorrentes (3+ ocorr√™ncias)"""
    if not history:
        return False, []

    historical_issues = []
    for record in history:
        historical_issues.extend(record.get("issues", []))

    if not historical_issues:
        return False, []

    recurring = []

    for current in current_issues:
        occurrence_count = 1

        for historical in historical_issues:
            similarity = _issue_similarity(current, historical)
            if similarity >= ISSUE_SIMILARITY_THRESHOLD:
                occurrence_count += 1

        if occurrence_count >= threshold:
            recurring.append({**current, "occurrence_count": occurrence_count})

    return len(recurring) > 0, recurring


def get_recurring_issue_summary(history: list[dict]) -> dict:
    """Analisa hist√≥rico para issues mais comuns"""
    all_issues = []
    for record in history:
        all_issues.extend(record.get("issues", []))

    if not all_issues:
        return {"total_issues": 0, "unique_issues": 0, "most_common": []}

    # Agrupar issues similares
    issue_groups = {}
    for issue in all_issues:
        key = _normalize_issue_key(issue)
        matched = False

        for existing_key in issue_groups:
            if SequenceMatcher(None, key, existing_key).ratio() >= ISSUE_SIMILARITY_THRESHOLD:
                issue_groups[existing_key].append(issue)
                matched = True
                break

        if not matched:
            issue_groups[key] = [issue]

    # Top 5 mais comuns
    sorted_groups = sorted(issue_groups.items(), key=lambda x: len(x[1]), reverse=True)

    most_common = []
    for key, issues in sorted_groups[:5]:
        most_common.append({
            "title": issues[0].get("title", key),
            "file": issues[0].get("file"),
            "occurrences": len(issues),
        })

    # Estat√≠sticas
    approved_count = sum(1 for r in history if r.get("status") == "approved")
    rejected_count = sum(1 for r in history if r.get("status") == "rejected")

    return {
        "total_issues": len(all_issues),
        "unique_issues": len(issue_groups),
        "most_common": most_common,
        "iterations_approved": approved_count,
        "iterations_rejected": rejected_count,
        "fix_success_rate": approved_count / len(history) if history else 0,
    }
```

---

### 7.3 Prompts Base (Adaptados para Skybridge)

#### 7.3.1 QA Reviewer Prompt (`prompts/qa_reviewer.md`)

```markdown
## YOUR ROLE - QA REVIEWER AGENT

You are **Quality Assurance Agent** in Skybridge development process. Your job is to validate that implementation is complete, correct, and production-ready before final sign-off.

**Key Principle**: You are the last line of defense. Be thorough.

---

## WHY QA VALIDATION MATTERS

The Agent may have:
- Completed all subtasks but missed edge cases
- Written code without necessary validation
- Introduced security vulnerabilities
- Broken existing functionality

Your job is to catch ALL of these before sign-off.

---

## PHASE 0: LOAD CONTEXT (MANDATORY)

```bash
# 1. Read spec
cat spec.md

# 2. Read worktree snapshot
cat .skybridge/worktree_snapshot.json

# 3. Read git diff from snapshot
# (Snapshot contains diff between initial and final state)
```

---

## PHASE 1: VERIFY SUBTASKS COMPLETED

Check if all subtasks in the job are marked as completed:
- Agent tasks completed
- Files modified
- Changes committed to worktree

---

## PHASE 2: CODE REVIEW

### 2.1: Security Review
Check for common vulnerabilities:
- SQL injection
- XSS (if web frontend)
- Hardcoded secrets (passwords, api_keys, tokens)
- Input validation

```bash
# Security checks
grep -rE "(password|secret|api_key|token)\s*=\s*['\"][^'\"]+['\"]" --include="*.py"
```

### 2.2: Code Quality
- Follows Skybridge patterns (Result, Envelope, Registry)
- Proper error handling
- Type hints present
- No debug prints in production code

### 2.3: Functional Verification
- Core functionality works as per spec
- Edge cases handled
- Error states return proper errors

---

## PHASE 3: GENERATE QA REPORT

Create comprehensive report:

```markdown
# QA Validation Report

## Summary
| Category | Status | Details |
|----------|--------|---------|
| Subtasks Complete | ‚úì/‚úó | X/Y completed |
| Code Quality | ‚úì/‚úó | [summary] |
| Security | ‚úì/‚úó | [summary] |
| Functional | ‚úì/‚úó | [summary] |

## Issues Found

### Critical (Blocks Sign-off)
1. [Issue description] - [File/Location]
2. [Issue description] - [File/Location]

### Major (Should Fix)
1. [Issue description] - [File/Location]

### Minor (Nice to Fix)
1. [Issue description] - [File/Location]

## Verdict

**SIGN-OFF**: [APPROVED / REJECTED]

**Reason**: [Explanation]

**Next Steps**:
- [If approved: Ready for merge to main branch]
- [If rejected: List of fixes needed, QA will re-run]
```

---

## PHASE 4: UPDATE IMPLEMENTATION PLAN

### If APPROVED:
```json
{
  "qa_signoff": {
    "status": "approved",
    "timestamp": "[ISO timestamp]",
    "qa_session": [session-number],
    "report_file": "qa_report.md",
    "verified_by": "qa_agent"
  }
}
```

### If REJECTED:
```json
{
  "qa_signoff": {
    "status": "rejected",
    "timestamp": "[ISO timestamp]",
    "qa_session": [session-number],
    "issues_found": [
      {
        "type": "critical|major|minor",
        "title": "[issue title]",
        "location": "[file:line]",
        "fix_required": "[description]"
      }
    ],
    "fix_request_file": "QA_FIX_REQUEST.md"
  }
}
```

---

## KEY REMINDERS

### Be Thorough
- Don't assume Agent did everything right
- Check EVERYTHING in spec
- Look for what's MISSING, not just what's wrong

### Be Specific
- Exact file paths (relative to worktree root)
- Reproducible steps for issues
- Clear fix instructions

### Be Fair
- Minor style issues don't block sign-off
- Focus on functionality and correctness
- Consider spec requirements, not perfection

### Document Everything
- Every check you run
- Every issue you find
- Every decision you make

---

## BEGIN
```

---

#### 7.3.2 QA Fixer Prompt (`prompts/qa_fixer.md`)

```markdown
## YOUR ROLE - QA FIX AGENT

You are **QA Fix Agent** in Skybridge development process. The QA Reviewer has found issues that must be fixed before sign-off. Your job is to fix ALL issues efficiently and correctly.

**Key Principle**: Fix what QA found. Don't introduce new issues. Get to approval.

---

## WHY QA FIX EXISTS

The QA Agent found issues that block sign-off:
- Missing validation
- Security vulnerabilities
- Code quality issues
- Missing functionality

You must fix these issues so QA can approve.

---

## PHASE 0: LOAD CONTEXT (MANDATORY)

```bash
# 1. Read QA fix request
cat QA_FIX_REQUEST.md

# 2. Read QA report
cat qa_report.md

# 3. Read spec
cat spec.md

# 4. Read worktree snapshot
cat .skybridge/worktree_snapshot.json
```

---

## PHASE 1: PARSE FIX REQUIREMENTS

From `QA_FIX_REQUEST.md`, extract:
- Issue titles
- File locations
- Problems
- Required fixes
- Verification criteria

Create mental checklist - you must address EVERY issue.

---

## PHASE 2: FIX ISSUES ONE BY ONE

For each issue:
1. Read problem area
2. Understand what's wrong
3. Implement minimal fix needed
4. Test locally (run tests if available)
5. Verify fix

**Follow these rules:**
- Make MINIMAL change needed
- Don't refactor surrounding code
- Don't add features
- Match Skybridge patterns (Result, Envelope)
- Test after each fix

---

## PHASE 3: RUN TESTS

After all fixes are applied:
- Run test suite (pytest, etc)
- Verify all tests pass
- Check for regressions

---

## PHASE 4: COMMIT FIXES

```bash
# Add all changes (excluding .skybridge/)
git add ':!.skybridge'

# Commit with message
git commit -m "fix: Address QA issues (qa-requested)"
```

---

## PHASE 5: UPDATE IMPLEMENTATION PLAN

```json
{
  "qa_signoff": {
    "status": "fixes_applied",
    "timestamp": "[ISO timestamp]",
    "fix_session": [session-number],
    "issues_fixed": [
      {
        "title": "[issue title]",
        "fix_commit": "[commit hash]"
      }
    ],
    "ready_for_qa_revalidation": true
  }
}
```

---

## COMMON FIX PATTERNS

### Missing Validation
- Add input validation checks
- Add error handling for edge cases
- Validate user inputs

### Security Issue
- Remove hardcoded secrets
- Add sanitization for inputs
- Implement proper authentication

### Code Quality
- Follow Skybridge patterns
- Add type hints
- Remove debug prints
- Improve error messages

---

## KEY REMINDERS

### Fix What Was Asked
- Don't add features
- Don't refactor
- Just fix the issues

### Be Thorough
- Every issue in QA_FIX_REQUEST.md
- Verify each fix

### Test After Fixes
- Run full test suite
- Check for regressions

### Don't Break Other Things
- Run full test suite to catch regressions
- Verify existing functionality still works

---

## BEGIN
```

---

### 7.3.3 Integra√ß√£o com JobOrchestrator

```python
"""
Job Orchestrator com QA Loop - Skybridge Adaptation
=====================================================

Integra QA Loop como fase p√≥s-execu√ß√£o de job.
"""

from pathlib import Path
from skybridge.core.contexts.qa.loop import QALoopOrchestrator
from skybridge.core.contexts.webhooks.application.job_orchestrator import JobOrchestrator


class QADrivenJobOrchestrator(JobOrchestrator):
    """
    Orquestrador de jobs com QA Loop.

    Workflow:
    1. JobOrchestrator executa job padr√£o
    2. Ap√≥s completion, inicia QA Loop
    3. QA Loop valida e corrige at√© aprova√ß√£o
    4. Se aprovado ‚Üí sign-off (pronto para merge)
    5. Se falhou ‚Üí worktree preservado para inspe√ß√£o
    """

    async def execute_job(self, job_id: str) -> Result[dict, str]:
        """
        Executa job completo com QA Loop.

        Fluxo:
        1. Executar job padr√£o (agent, worktree, snapshot)
        2. Verificar se job completou com sucesso
        3. Iniciar QA Loop
        4. Retornar resultado final
        """
        # 1. Executar job padr√£o
        result = await super().execute_job(job_id)

        if result.is_err:
            return result

        # 2. Iniciar QA Loop se job completou
        job = await self.job_queue.get_job(job_id)
        if job.status != "completed":
            return Result.ok({
                "message": "Job n√£o completado, QA n√£o iniciado",
                "qa_status": "not_run"
            })

        # 3. Iniciar QA Loop
        qa_loop = QALoopOrchestrator(
            job_queue=self.job_queue,
            agent_adapter=self.agent_adapter,
            project_dir=self.project_dir,
        )

        qa_approved = await qa_loop.run_qa_validation_loop(
            spec_dir=job.worktree_path,
            model="sonnet",
        )

        # 4. Retornar resultado
        return Result.ok({
            "message": "Job completado com QA",
            "qa_status": "approved" if qa_approved else "failed",
            "worktree_preserved": True,
        })
```

---

## 8. Roadmap de Implementa√ß√£o

### 8.1 Phase 1: MVP (1-2 semanas)

**Objetivo:** QA Loop b√°sico com valida√ß√£o e corre√ß√£o

**Entreg√°veis:**
- [x] QA Loop Orchestrator b√°sico
- [x] QA Reviewer Agent simples
- [x] QA Fixer Agent simples
- [x] Criteria Management (approved/rejected)
- [x] Iteration History tracking
- [x] Relat√≥rios de QA (qa_report.md)
- [x] QA Fix Request (QA_FIX_REQUEST.md)
- [ ] Recurring issue detection
- [ ] Escalation logic

**Crit√©rios de Sucesso:**
- [x] Loop roda itera√ß√µes
- [x] Rejected ‚Üí Fixer ‚Üí Re-review
- [x] Approved ‚Üí Sign-off
- [x] Atualiza implementation_plan.json

---

### 8.2 Phase 2: Enhanced (2-3 semanas)

**Objetivo:** Detec√ß√£o de issues recorrentes e escalonamento

**Entreg√°veis:**
- [x] Recurring issue detection (SequenceMatcher)
- [x] Issue similarity scoring (threshold 0.8)
- [x] Escalation (QA_ESCALATION.md)
- [x] Iteration statistics
- [x] Most common issues tracking

**Crit√©rios de Sucesso:**
- [x] Detecta issues que aparecem 3+ vezes
- [x] Escalona automaticamente
- [x] Cria relat√≥rio detalhado

---

### 8.3 Phase 3: Memory Integration (3-4 semanas)

**Objetivo:** Integra√ß√£o com sistema de mem√≥ria (Graphiti ou similar)

**Entreg√°veis:**
- [ ] Memory context retrieval (patterns, gotchas)
- [ ] Session insights saving
- [ ] Cross-session learning

**Crit√©rios de Sucesso:**
- [ ] Recupera contexto antes de cada sess√£o QA
- [ ] Salva descobertas ap√≥s sess√£o
- [ ] Usa contexto em pr√≥ximas sess√µes

---

### 8.4 Phase 4: E2E Testing (4-5 semanas)

**Objetivo:** Testing E2E autom√°tico para web frontends

**Entreg√°veis:**
- [ ] Browser automation (Puppeteer)
- [ ] Screenshot capture
- [ ] Form interaction testing
- [ ] Console error checking

**Crit√©rios de Sucesso:**
- [ ] QA toma screenshots antes/depois
- [ ] QA interage com UI via comandos
- [ ] Verifica console errors
- [ ] Documenta findings

---

### 8.5 Phase 5: No-Test Handling (5-6 semanas)

**Objetivo:** Criar planos de teste manual para projetos sem testes

**Entreg√°veis:**
- [ ] No-test project detection
- [ ] Manual test plan generation
- [ ] Test framework scanning (pytest, jest, vitest)

**Crit√©rios de Sucesso:**
- [ ] Detecta aus√™ncia de testes
- [ ] Cria MANUAL_TEST_PLAN.md
- [ ] Sugere testes manuais

---

### 8.6 Phase 6: Linear Integration (6-7 semanas, opcional)

**Objetivo:** Integra√ß√£o com Linear para rastreamento de tasks

**Entreg√°veis:**
- [ ] Linear client wrapper
- [ ] Task state management
- [ ] Status updates (In Review, Approved, Failed)

**Crit√©rios de Sucesso:**
- [ ] Atualiza status no Linear
- [ ] Cria task de QA no Linear
- [ ] Rastreia itera√ß√µes

---

## 9. Diferen√ßas de Implementa√ß√£o

### 9.1 Skybridge vs Auto-Claude

| Aspecto | Auto-Claude | Skybridge (Alvo) | Diferen√ßa |
|----------|-------------|-------------------|------------|
| **Claude Client** | SDK customizado | ClaudeCodeAdapter | Similiar |
| **Prompt Loading** | Prompts est√°ticos | Mesma abordagem |
| **Memory** | Graphiti obrigat√≥rio | Opcional (fase 3) |
| **E2E Testing** | Electron MCP | Puppeteer/Playwright |
| **Git Operations** | Direto no worktree | Atrav√©s de worktree_manager |
| **Linear** | Integrado | Opcional |
| **Spec Structure** | .auto-claude/specs/ | Worktree direto |

---

### 9.2 Adapta√ß√µes Necess√°rias para Skybridge

**Claude Client:**
- Skybridge usa `ClaudeCodeAdapter` (infra/agents/claude_agent.py)
- Auto-Claude usa `create_client()` (core/client.py)
- **A√ß√£o:** Usar ClaudeCodeAdapter ou adaptar create_client

**Worktree:**
- Skybridge j√° tem worktree_manager
- Auto-Claude usa git diretamente no worktree
- **A√ß√£o:** Integrar com worktree_manager existente

**Snapshot:**
- Skybridge tem GitExtractor (snapshot inicial)
- Auto-Claude n√£o tem snapshot formal
- **A√ß√£o:** Capturar snapshot antes de QA (j√° existe, s√≥ adicionar p√≥s-QA)

**Memory:**
- Skybridge n√£o tem Graphiti
- Auto-Claude Graphiti √© obrigat√≥rio
- **A√ß√£o:** Implementar sistema de mem√≥ria simples (JSON + embeddings) ou esperar Graphiti

**Spec Directory:**
- Skybridge usa worktree_path como spec_dir
- Auto-Claude usa .auto-claude/specs/
- **A√ß√£o:** Passar worktree_path diretamente para QA agents

---

## 10. Teste e Valida√ß√£o

### 10.1 Crit√©rios de Aceita√ß√£o de QA

Para validar implementa√ß√£o, verificar:

**MVP (Phase 1):**
- [ ] QA Loop inicia ap√≥s job completion
- [ ] Itera√ß√£o 1 executa QA Reviewer
- [ ] Se rejeitado, QA Fixer corrige issues
- [ ] Itera√ß√£o 2 revalida
- [ ] Continua at√© approved ou max 50 itera√ß√µes
- [ ] Implementation plan atualizado com status

**Enhanced (Phase 2):**
- [ ] Issues recorrentes detectados (3+ ocorr√™ncias)
- [ ] Escalona para humano quando recorrentes
- [ ] QA_ESCALATION.md criado
- [ ] Iteration statistics calculadas

---

### 10.2 Casos de Teste

**Cen√°rio 1: Approved na primeira itera√ß√£o**
```
1. Job executa agent (/resolve-issue)
2. Worktree criado e modificado
3. QA Reviewer valida
4. Todos crit√©rios passam
5. Status: "approved"
6. Sign-off gravado em implementation_plan.json
7. Worktree preservado para merge manual
```

**Cen√°rio 2: Rejeitado na primeira, aprovado na segunda**
```
1. QA Reviewer encontra issue
2. Status: "rejected"
3. QA Fixer corrige issue
4. Status: "fixes_applied"
5. QA Reviewer re-valida
6. Todos crit√©rios passam
7. Status: "approved"
8. Sign-off gravado
```

**Cen√°rio 3: Issues recorrentes**
```
1. Issue aparece 3 vezes (itera√ß√µes 1, 3, 5)
2. Detec√ß√£o de recurring issue acionada
3. QA_ESCALATION.md criado
4. Loop termina com status "failed"
5. Worktree preservado para inspe√ß√£o manual
```

**Cen√°rio 4: Erro consecutivo (3 vezes)**
```
1. QA Reviewer falha 3 vezes sem progresso
2. Detecta MAX_CONSECUTIVE_ERRORS atingido
3. Loop termina com status "failed"
4. Erros documentados em iteration history
```

---

### 10.3 M√©tricas de Sucesso

**Quantitativas:**
- Taxa de aprova√ß√£o em primeiras 3 itera√ß√µes
- N√∫mero m√©dio de itera√ß√µes at√© aprova√ß√£o
- Percentual de issues recorrentes
- Tempo m√©dio por itera√ß√£o

**Qualitativas:**
- QA est√° detectando bugs reais?
- QA est√° criando falsos positivos?
- Fixes est√£o resolvendo issues?
- Escalonamento est√° apropriado?

---

## 11. Recomenda√ß√µes Finais

### 11.1 Prioridade de Implementa√ß√£o

**CR√çTICO (implementar primeiro):**
1. QA Loop b√°sico (reviewer + fixer)
2. Criteria management
3. Iteration history tracking
4. Status persistence (implementation_plan.json)

**ALTA (implementar depois):**
5. Recurring issue detection
6. Escalation logic
7. Memory integration b√°sica (JSON local)
8. E2E testing (Puppeteer/Playwright)

**M√âDIA (implementar depois):**
9. Graphiti memory integration
10. Linear integration
11. Advanced QA features (test framework detection, manual test plans)

**BAIXA (implementar depois):**
12. Electron MCP (se Skybridge tiver Electron frontend)

---

### 11.2 Boas Pr√°ticas

**Design:**
- Separar concerns: reviewer (valida√ß√£o) vs fixer (corre√ß√£o)
- Usar Result pattern para error handling
- Manter state em JSON (implementation_plan.json)
- Logging detalhado para debugging

**Seguran√ßa:**
- Validar todos os fixes antes de aprova√ß√£o
- Verificar regress√µes ap√≥s cada fix
- N√£o permitir que QA fixer introduza novos bugs

**Performance:**
- Limitar n√∫mero de itera√ß√µes (max: 50)
- Timeout em cada sess√£o de QA
- Early termination se sem progresso

**Experi√™ncia do Desenvolvedor:**
- Worktree sempre preservado (Skybridge RF005)
- Logs detalhados de cada itera√ß√£o
- Relat√≥rios em Markdown leg√≠veis
- Mensagens claras de progresso

---

## 12. Refer√™ncias

### 12.1 Auto-Claude

- **QA Loop:** `apps/backend/qa/loop.py`
- **Reviewer:** `apps/backend/qa/reviewer.py`
- **Fixer:** `apps/backend/qa/fixer.py`
- **Criteria:** `apps/backend/qa/criteria.py`
- **Report:** `apps/backend/qa/report.py`
- **Prompts:**
  - `apps/backend/prompts/qa_reviewer.md`
  - `apps/backend/prompts/qa_fixer.md`
- **Memory:** `apps/backend/agents/memory_manager.py`

---

### 12.2 Skybridge

- **Worktree Manager:** `src/skybridge/core/contexts/webhooks/application/worktree_manager.py`
- **Job Orchestrator:** `src/skybridge/core/contexts/webhooks/application/job_orchestrator.py`
- **Agent Facade:** `src/skybridge/core/contexts/webhooks/infrastructure/agents/claude_agent.py`
- **Snapshot Extractor:** `src/skybridge/platform/observability/snapshot/extractors/git_extractor.py`
- **Domain:** `src/skybridge/core/contexts/webhooks/domain/`
- **Ports:** `src/skybridge/core/contexts/webhooks/ports/`

---

## 13. Conclus√£o

### 13.1 Resumo Executivo

O **QA Loop** do Auto-Claude √© um sistema robusto de valida√ß√£o autom√°tica com:

**Componentes Principais:**
1. QA Loop Orchestrator - Coordena itera√ß√µes at√© aprova√ß√£o/limite
2. QA Reviewer Agent - Valida acceptance criteria, executa testes
3. QA Fixer Agent - Corrige issues encontradas pelo reviewer
4. Criteria Management - Gerencia acceptance criteria e status
5. Report & Tracking - Rastreia hist√≥rico, detecta issues recorrentes
6. Memory Integration - Graphiti para contexto cross-session
7. E2E Testing - Electron MCP para valida√ß√£o de UI

**Principais Vantagens:**
- ‚úÖ Self-validating (detecta e corrige automaticamente)
- ‚úÖ Iteration tracking (hist√≥rico completo)
- ‚úÖ Recurring issue detection (3+ ocorr√™ncias)
- ‚úÖ Escalation autom√°tica (humano quando necess√°rio)
- ‚úÖ Memory integration (aprende com sess√µes anteriores)
- ‚úÖ Graceful degradation (n√£o trava sem memory)

---

### 13.2 Skybridge - Estado Atual

**O que Skybridge J√Å tem:**
- ‚úÖ Worktree management
- ‚úÖ Snapshot captura (GitExtractor)
- ‚úÖ Job queue ass√≠ncrona
- ‚úÖ Agent framework (ClaudeCodeAdapter)

**O que Skybridge N√ÉO tem (GAP):**
- ‚ùå QA Loop orchestration
- ‚ùå QA reviewer agent
- ‚ùå QA fixer agent
- ‚ùå Criteria management system
- ‚ùå Iteration history tracking
- ‚ùå Recurring issue detection
- ‚ùå Escalation logic
- ‚ùå QA reports (qa_report.md)
- ‚ùå Memory integration
- ‚ùå E2E testing

---

### 13.3 Caminho de Implementa√ß√£o

**Fase 1 (1-2 semanas):** QA Loop b√°sico
- Criar estrutura de m√≥dulo QA
- Implementar QA reviewer agent (valida√ß√£o simples)
- Implementar QA fixer agent (corre√ß√£o simples)
- Implementar criteria management (approved/rejected)
- Criar iteration history tracking
- Integrar com JobOrchestrator (p√≥s-execu√ß√£o de job)

**Fase 2 (2-3 semanas):** Recurring issues & escalonamento
- Implementar recurring issue detection (SequenceMatcher)
- Criar l√≥gica de escalonamento
- Criar relat√≥rios de escalonamento (QA_ESCALATION.md)
- Adicionar statistics de itera√ß√µes

**Fase 3 (3-4 semanas):** Memory integration
- Implementar sistema de mem√≥ria local (JSON + embeddings)
- Ou integrar com Graphiti (se dispon√≠vel)
- Context retrieval antes de sess√µes QA
- Session insights saving ap√≥s sess√µes

**Fase 4 (4-5 semanas):** E2E testing
- Implementar browser automation (Puppeteer/Playwright)
- Criar screenshot capture
- Implementar form interaction testing
- Integrar com QA reviewer prompts

**Fase 5 (5-6 semanas):** Avan√ßado
- Test framework detection
- Manual test plans
- Graphiti memory
- Linear integration (opcional)

---

> "QA autom√°tico √© a linha de defesa que protege produ√ß√£o de bugs." ‚Äì made by Sky üõ°Ô∏è
