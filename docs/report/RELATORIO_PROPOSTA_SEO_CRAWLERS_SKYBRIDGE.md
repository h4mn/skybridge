# Proposta SEO: EstratÃ©gia de Visibilidade para Skybridge

**Data:** 2026-02-08
**Autor:** Sky
**Tipo:** Proposta TÃ©cnica e EstratÃ©gica
**Prioridade:** MÃ©dia
**Relacionado:** PB002 (Ngrok), PRD022 (Servidor Unificado)

---

## Resumo Executivo

**Problema Identificado:** A Skybridge estÃ¡ sendo descoberta por crawlers (Bingbot, Googlebot) via Ngrok pÃºblico, mas sem estratÃ©gia definida para aproveitar esse trÃ¡fego.

**Oportunidade:** Transformar crawlers de "intrusos" em **propaganda automÃ¡tica** da Skybridge, indexando documentaÃ§Ã£o e tornando o projeto descobrÃ­vel via motores de busca.

**Impacto Esperado:**
- Maior visibilidade do projeto
- Novos contribuidores via busca orgÃ¢nica
- DocumentaÃ§Ã£o indexada automaticamente
- Autoridade tÃ©cnica no nicho de AI automation

---

## AnÃ¡lise do CenÃ¡rio Atual

### Descoberta: Logs de Acesso de Crawlers

**Data:** 2026-02-08 11:32:04
**Origem:** Microsoft Azure (ASN AS8075)
**IP:** 104.210.140.136
**User-Agent:** Bingbot

```
GET /robots.txt â†’ 404 (0.51ms)
```

### Estado Atual do Ngrok

```bash
NGROK_ENABLED=true
NGROK_DOMAIN=cunning-dear-primate.ngrok-free.app
```

**Problema:** DomÃ­nio pÃºblico, sem autenticaÃ§Ã£o, exposto a crawlers.

### Endpoints JÃ¡ Acessados por Crawlers

Baseado em logs de 2026-02-07:

| Endpoint | Acessado? | ConteÃºdo |
|----------|-----------|----------|
| `/robots.txt` | âŒ 404 | NÃ£o existe |
| `/api/openapi` | âœ… 200 | EspecificaÃ§Ã£o OpenAPI |
| `/api/privacy` | âœ… 200 | PolÃ­tica de privacidade |
| `/api/health` | âœ… 200 | Health check |
| `/api/kanban/lists` | âœ… 200 | Dados do Kanban |
| `/api/kanban/cards` | âœ… 200 | Cards do Kanban |
| `/docs` | âœ… 200 | DocumentaÃ§Ã£o Swagger UI |
| `/redoc` | âœ… 200 | DocumentaÃ§Ã£o ReDoc |

**ConclusÃ£o:** Crawlers JÃ exploram a API e documentaÃ§Ã£o. Sem `robots.txt`, eles seguem links padrÃ£o.

---

## EstratÃ©gia Proposta: SEO para APIs

### PrincÃ­pio Fundamental

> **"NÃ£o bloquee. Converta."**

Em vez de bloquear crawlers, direcionÃ¡-los para conteÃºdo que promove a Skybridge.

### Arquitetura da SoluÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CRAWLER CHEGA                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. /robots.txt                                                  â”‚
â”‚     â†’ Permite /docs, /redoc, /api/openapi                        â”‚
â”‚     â†’ Bloqueia /api/logs/, /api/webhooks/                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Detector de Crawlers (middleware)                           â”‚
â”‚     â†’ Identifica user-agent de bots                             â”‚
â”‚     â†’ Redireciona / â†’ /docs                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. OpenAPI Enriquecida                                          â”‚
â”‚     â†’ DescriÃ§Ã£o completa da Skybridge                           â”‚
â”‚     â†’ Links para GitHub, ADRs, PRDs                             â”‚
â”‚     â†’ Marketing automÃ¡tico                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. /api/health com _meta                                        â”‚
â”‚     â†’ URLs de registro para bots indexarem                      â”‚
â”‚     â†’ DescriÃ§Ã£o do projeto                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Telemetria de Crawlers                                       â”‚
â”‚     â†’ Logger dedicado para rastrear                            â”‚
â”‚     â†’ Analisar quem nos encontra                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ImplementaÃ§Ã£o Detalhada

### 1. robots.txt EstratÃ©gico

**LocalizaÃ§Ã£o:** `apps/web/public/robots.txt` (ou rota `/robots.txt`)

```txt
# robots.txt - Skybridge API
# Direciona crawlers para documentaÃ§Ã£o pÃºblica

User-agent: *
# Permitir documentaÃ§Ã£o
Allow: /docs$
Allow: /redoc$
Allow: /api/openapi$
Allow: /api/health$

# Bloquear endpoints sensÃ­veis
Disallow: /api/logs/
Disallow: /api/webhooks/
Disallow: /api/workspaces/
Disallow: /api/agents/
Disallow: /api/kanban/

# Sitemap (futuro)
Sitemap: https://cunning-dear-primate.ngrok-free.app/sitemap.xml
```

**ImplementaÃ§Ã£o em cÃ³digo:**

```python
# src/runtime/delivery/seo_routes.py

from fastapi import Response

@app.get("/robots.txt")
async def robots_txt():
    """robots.txt otimizado para SEO de APIs."""
    return Response(
        content="""User-agent: *
Allow: /docs$
Allow: /redoc$
Allow: /api/openapi$
Allow: /api/health$

Disallow: /api/logs/
Disallow: /api/webhooks/
Disallow: /api/workspaces/
Disallow: /api/agents/
Disallow: /api/kanban/

Sitemap: https://cunning-dear-primate.ngrok-free.app/sitemap.xml
""",
        media_type="text/plain",
        headers={"Cache-Control": "public, max-age=86400"}
    )
```

---

### 2. Detector de Crawlers com Redirecionamento

**LocalizaÃ§Ã£o:** `src/runtime/delivery/seo_middleware.py`

```python
import re
from fastapi import Request, Response
from fastapi.responses import RedirectResponse

USER_AGENT_PATTERNS = [
    r'bot', r'crawler', r'spider', r'scraper',
    r'googlebot', r'bingbot', r'slurp', r'duckduckbot',
    r'baiduspider', r'yandexbot', r'facebookexternalhit'
]

def is_crawler(request: Request) -> bool:
    """Detecta se requisiÃ§Ã£o vem de crawler conhecido."""
    user_agent = request.headers.get('user-agent', '')
    return any(re.search(p, user_agent, re.I) for p in USER_AGENT_PATTERNS)

@app.middleware("http")
async def crawler_redirector(request: Request, call_next):
    """Redireciona crawlers para documentaÃ§Ã£o."""
    # NÃ£o afeta requisiÃ§Ãµes de API
    if request.url.path.startswith('/api/'):
        return await call_next(request)

    # Se for crawler acessando raiz, redireciona para docs
    if is_crawler(request) and request.url.path == '/':
        return RedirectResponse(
            url='/docs',
            status_code=302,
            headers={
                "X-Crawler-Detected": "true",
                "X-Redirect-Reason": "SEO: documentation index"
            }
        )

    return await call_next(request)
```

---

### 3. OpenAPI Enriquecida

**LocalizaÃ§Ã£o:** `src/runtime/bootstrap/app.py`

```python
app = FastAPI(
    title="ğŸŒ‰ Skybridge - AI Automation Bridge",
    description="""
    ## ğŸŒ‰ Skybridge

    **Ponte entre intenÃ§Ã£o humana e execuÃ§Ã£o assistida por IA.**

    A Skybridge Ã© uma plataforma de automaÃ§Ã£o que conecta:
    - ğŸ”„ Webhooks do GitHub e Trello
    - ğŸ¤– Agentes autÃ´nomos Claude SDK
    - ğŸ“Š Kanban sincronizado em tempo real
    - ğŸ› ï¸ Workspaces git isolados

    ### ğŸ¯ Funcionalidades Principais

    - **Webhooks AutÃ´nomos:** Receba eventos do GitHub/Trello e deixe agentes resolverem
    - **Kanban Vivo:** Cards sincronizados com Trello em tempo real via SSE
    - **Multi-Workspace:** InstÃ¢ncias isoladas para diferentes contextos
    - **Agentes SDK:** IntegraÃ§Ã£o nativa com Claude Agent SDK

    ### ğŸ“š DocumentaÃ§Ã£o

    - [GitHub](https://github.com/h4mn/skybridge) - CÃ³digo fonte
    - [ADRs](https://github.com/h4mn/skybridge/tree/main/docs/adr) - DecisÃµes arquiteturais
    - [PRDs](https://github.com/h4mn/skybridge/tree/main/docs/prd) - EspecificaÃ§Ãµes
    - [Playbooks](https://github.com/h4mn/skybridge/tree/main/docs/playbook) - Guias prÃ¡ticos

    ### ğŸš€ ComeÃ§ando

    ```bash
    git clone https://github.com/h4mn/skybridge.git
    cd skybridge
    python -m apps.api.main
    ```

    ---
    *Powered by Claude Opus 4.6 | Made with â¤ï¸ by the Skybridge community*
    """,
    version="0.13.0.dev",
    contact={
        "name": "Skybridge Project",
        "url": "https://github.com/h4mn/skybridge",
        "email": "noreply@github.com"
    },
    license_info={
        "name": "MIT",
        "url": "https://github.com/h4mn/skybridge/blob/main/LICENSE",
    },
    tags=[
        {"name": "webhooks", "description": "Webhook management"},
        {"name": "kanban", "description": "Kanban board operations"},
        {"name": "workspaces", "description": "Workspace management"},
        {"name": "agents", "description": "AI agent operations"},
        {"name": "observability", "description": "Logs and metrics"},
    ]
)
```

---

### 4. Health Endpoint com Metadados

**LocalizaÃ§Ã£o:** `src/runtime/delivery/health_routes.py`

```python
from fastapi import Request

@app.get("/api/health")
async def health_check(request: Request):
    """Health check com metadados para crawlers."""
    base_response = {
        "status": "healthy",
        "version": "0.13.0.dev",
        "timestamp": datetime.utcnow().isoformat()
    }

    # Se for crawler, adiciona metadados descoberta
    if is_crawler(request):
        base_response["_meta"] = {
            "project": "Skybridge",
            "description": "Ponte entre intenÃ§Ã£o humana e execuÃ§Ã£o por IA",
            "repository": "https://github.com/h4mn/skybridge",
            "docs": f"{request.url.scheme}://{request.url.netloc}/docs",
            "openapi": f"{request.url.scheme}://{request.url.netloc}/api/openapi",
            "webhook": "https://github.com/h4mn/skybridge/dispatches",
            "stars": "https://github.com/h4mn/skybridge/stargazers",
            "tags": ["ai", "automation", "webhooks", "trello", "github", "agents"]
        }

    return base_response
```

---

### 5. Telemetria de Crawlers

**LocalizaÃ§Ã£o:** `src/core/observability/crawlers.py`

```python
import logging
from datetime import datetime

crawler_logger = logging.getLogger("skybridge.crawlers")

@app.middleware("http")
async def crawler_tracker(request: Request, call_next):
    """Rastreia acessos de crawlers para analytics."""
    user_agent = request.headers.get('user-agent', '')

    if is_crawler(request):
        crawler_logger.info(
            f"[CRAWLER] {datetime.utcnow().isoformat()} | "
            f"{request.client.host} | "
            f"{user_agent[:100]} | "
            f"{request.method} {request.url.path}"
        )

        # Persistir estatÃ­sticas (opcional)
        # await crawler_stats.increment(request.url.path)

    return await call_next(request)
```

**ConfiguraÃ§Ã£o de logging:**

```python
# src/core/observability/logging_config.py

crawler_handler = RotatingFileHandler(
    "logs/crawlers.log",
    maxBytes=1_000_000,
    backupCount=5
)
crawler_handler.setFormatter(
    Formatter('%(asctime)s | %(levelname)s | %(message)s')
)

crawler_logger = logging.getLogger("skybridge.crawlers")
crawler_logger.addHandler(crawler_handler)
crawler_logger.setLevel(logging.INFO)
```

---

## Plano de ImplementaÃ§Ã£o

### Fase 1: Quick Wins (1-2 horas)

| ID | Tarefa | Arquivo | Impacto |
|----|--------|---------|---------|
| 1.1 | Criar rota `/robots.txt` | `src/runtime/delivery/seo_routes.py` | Alto |
| 1.2 | Enriquecer OpenAPI | `src/runtime/bootstrap/app.py` | Alto |
| 1.3 | Adicionar `_meta` no `/api/health` | `src/runtime/delivery/health_routes.py` | MÃ©dio |

### Fase 2: Middleware de DetecÃ§Ã£o (2-3 horas)

| ID | Tarefa | Arquivo | Impacto |
|----|--------|---------|---------|
| 2.1 | Criar `is_crawler()` | `src/runtime/delivery/seo_middleware.py` | MÃ©dio |
| 2.2 | Redirecionar `/` para `/docs` | `src/runtime/delivery/seo_middleware.py` | MÃ©dio |
| 2.3 | Adicionar headers de debug | `src/runtime/delivery/seo_middleware.py` | Baixo |

### Fase 3: Telemetria (1-2 horas)

| ID | Tarefa | Arquivo | Impacto |
|----|--------|---------|---------|
| 3.1 | Logger dedicado `skybridge.crawlers` | `src/core/observability/crawlers.py` | Baixo |
| 3.2 | Dashboard de estatÃ­sticas | (opcional) | Baixo |

### Fase 4: ConteÃºdo (2-4 horas)

| ID | Tarefa | Arquivo | Impacto |
|----|--------|---------|---------|
| 4.1 | Criar sitemap.xml | `apps/web/public/sitemap.xml` | Alto |
| 4.2 | Otimizar descriÃ§Ãµes de tags OpenAPI | `src/runtime/bootstrap/app.py` | MÃ©dio |
| 4.3 | Adicionar exemplos em endpoints | OpenAPI specs | MÃ©dio |

---

## BenefÃ­cios Esperados

### Imediatos

1. **DocumentaÃ§Ã£o Indexada:** Bing/Google indexam `/docs` e `/api/openapi`
2. **Controle de Crawling:** Bloqueio de endpoints sensÃ­veis
3. **Direcionamento:** Crawlers vÃ£o para conteÃºdo relevante

### MÃ©dio Prazo (1-3 meses)

1. **Busca OrgÃ¢nica:** Pessoas encontram Skybridge via:
   - "AI automation GitHub Trello"
   - "Claude agent SDK integration"
   - "Webhook autonomous agents"

2. **Novos Contribuidores:** Visibilidade gera interesse

3. **Autoridade:** Posicionamento como referÃªncia tÃ©cnica

### Longo Prazo (3-12 meses)

1. **Comunidade:** Crescimento orgÃ¢nico
2. **Parcerias:** Descoberta por empresas/projetos
3. **MÃ©tricas:** Analytics mostra origem do trÃ¡fego

---

## Riscos e MitigaÃ§Ãµes

### Risco 1: Sobrecarga de Crawlers

**DescriÃ§Ã£o:** Crawlers podem fazer muitas requisiÃ§Ãµes.

**MitigaÃ§Ã£o:**
```python
# Rate limiting para crawlers
from slowapi import Limiter

limiter = Limiter(key_func=get_remote_address)

@app.get("/api/openapi")
@limiter.limit("10/minute")
async def openapi():
    ...
```

### Risco 2: IndexaÃ§Ã£o de Dados SensÃ­veis

**DescriÃ§Ã£o:** Crawlers podem indexar dados do Kanban.

**MitigaÃ§Ã£o:**
- `robots.txt` bloqueia `/api/kanban/`
- AutenticaÃ§Ã£o obrigatÃ³ria para dados reais
- Dados de desenvolvimento sÃ£o descartÃ¡veis

### Risco 3: DomÃ­nio Ngrok InstÃ¡vel

**DescriÃ§Ã£o:** DomÃ­nio muda se Ngrok restart.

**MitigaÃ§Ã£o:**
- Usar `NGROK_DOMAIN` reservado (jÃ¡ configurado)
- DocumentaÃ§Ã£o usa URLs relativas quando possÃ­vel

---

## MÃ©tricas de Sucesso

| MÃ©trica | Como Medir | Meta |
|---------|------------|------|
| IndexaÃ§Ã£o Bing/Google | `site:cunning-dear-primate.ngrok-free.app` | 10+ pÃ¡ginas |
| TrÃ¡fego OrgÃ¢nico | Analytics crawler requests | 100+/mÃªs |
| Novos Issues GitHub | "Encontrei via busca" label | 1+/mÃªs |
| Stars no RepositÃ³rio | Crescimento vs baseline | +10%/mÃªs |

---

## ConclusÃ£o e RecomendaÃ§Ã£o

### Resumo

A Skybridge estÃ¡ sendo descoberta por crawlers sem estratÃ©gia. Implementar SEO para APIs transforma "intrusos" em **propaganda automÃ¡tica**.

### RecomendaÃ§Ã£o

**âœ… APROVAR implementaÃ§Ã£o em fases:**

1. Fase 1 (Quick Wins) - **Implementar imediatamente**
2. Fase 2 (Middleware) - **Implementar na prÃ³xima sprint**
3. Fase 3 (Telemetria) - **Implementar se houver interesse**
4. Fase 4 (ConteÃºdo) - **Implementar conforme tempo disponÃ­vel**

### Next Steps

1. Aprovar esta proposta
2. Criar branch `feature/seo-crawlers`
3. Implementar Fase 1
4. Testar com Bing Webmaster Tools
5. Monitorar `logs/crawlers.log`

---

## ApÃªndice: Exemplo de Fluxo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Bingbot descobre domÃ­nio via Ngrok DNS                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Requisita: GET /robots.txt                                      â”‚
â”‚    Resposta: 200 com Allow: /docs, Disallow: /api/logs/            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Requisita: GET /docs                                            â”‚
â”‚    Resposta: 200 com OpenAPI enriquecida                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Indexa documentaÃ§Ã£o nos servidores do Bing                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. UsuÃ¡rio pesquisa: "AI automation bridge GitHub Trello"          â”‚
â”‚    Resultado: Skybridge API docs â†’ Clique                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. UsuÃ¡rio explora docs â†’ GitHub â†’ Star â†’ Contribui                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**DocumentaÃ§Ã£o Relacionada:**

- [PB002 - Ngrok URL Fixa](../playbook/PB002-Ngrok-URL-Fixa.md)
- [PRD022 - Servidor Unificado](../prd/PRD022-servidor-unificado.md)
- [ADR016 - OpenAPI HÃ­brido](../adr/ADR016-openapi-hibrido-estatico-dinamico.md)

---

> "Se nÃ£o pode vencer os crawlers, lidere-os" â€“ made by Sky ğŸŒ
